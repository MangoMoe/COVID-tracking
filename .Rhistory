mainDir = "./data/output/"
subDir = state
file_sub = paste(mainDir,subDir,sep="")
dir.create(file.path(mainDir, subDir))
# write.csv(restricted_state_df2,paste(file_sub,"/",state,"_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
#print(paste("Done writing csv for day ", toString(cutoff), " of " ,state,sep=""))
# break
#print(cbind(state_list,lm_mseS, grf_mseS))
write.csv(total_df,paste(mainDir,"allstates_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
}
# Training Set
restricted_state_df0 <- parLapply(makeCluster(detectCores()),state_list,test_set)
source("county_analysis.R")
makeCluster
makeCluster
# Training Set
restricted_state_df0 <- parLapply(makeCluster(detectCores()),state_list,test_set)
cl <- makeCluster(detectCores())
clusterExport(cl, list("county_analysis.R"))
cl <- makeCluster(detectCores())
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
cl
clusterExport(cl, list("county_analysis"))
f
for (cutoff in (latest_date - predictionsize-1):(latest_date - predictionsize)){
state_df_list <- list()
lm_mseS<-list()
grf_mseS<-list()
cutoff_S <-list()
state_S <-list()
total_df <- NULL
test_set <- function(state){
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
}
# Validation Set
restricted_state_df1 <- subset(county_data, days_from_start <= cutoff & days_from_start >= cutoff)
# Training Set
restricted_state_df0 <- parLapply(cl,state_list,test_set)
today<-restricted_state_df0[c("date","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
#lm_mseS<-list.append(lm_mseS,sum(restricted_state_df2$lm_mse))
#grf_mseS<-list.append(grf_mseS,sum(restricted_state_df2$grf_mse))
#cutoff_S<-list.append(cutoff_S,cutoff)
#state_S<-list.append(state_S,state)
total_df <- rbind(total_df,restricted_state_df2)
mainDir = "./data/output/"
subDir = state
file_sub = paste(mainDir,subDir,sep="")
dir.create(file.path(mainDir, subDir))
# write.csv(restricted_state_df2,paste(file_sub,"/",state,"_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
#print(paste("Done writing csv for day ", toString(cutoff), " of " ,state,sep=""))
# break
#print(cbind(state_list,lm_mseS, grf_mseS))
write.csv(total_df,paste(mainDir,"allstates_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
}
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
warnings(0)
warnings()
clusterExport(cl, list("test_set"))
for (cutoff in (latest_date - predictionsize-1):(latest_date - predictionsize)){
state_df_list <- list()
lm_mseS<-list()
grf_mseS<-list()
cutoff_S <-list()
state_S <-list()
total_df <- NULL
test_set <- function(state){
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
}
# Validation Set
restricted_state_df1 <- subset(county_data, days_from_start <= cutoff & days_from_start >= cutoff)
# Training Set
restricted_state_df0 <- parLapply(cl,state_list,test_set)
today<-restricted_state_df0[c("date","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
#lm_mseS<-list.append(lm_mseS,sum(restricted_state_df2$lm_mse))
#grf_mseS<-list.append(grf_mseS,sum(restricted_state_df2$grf_mse))
#cutoff_S<-list.append(cutoff_S,cutoff)
#state_S<-list.append(state_S,state)
total_df <- rbind(total_df,restricted_state_df2)
mainDir = "./data/output/"
subDir = state
file_sub = paste(mainDir,subDir,sep="")
dir.create(file.path(mainDir, subDir))
# write.csv(restricted_state_df2,paste(file_sub,"/",state,"_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
#print(paste("Done writing csv for day ", toString(cutoff), " of " ,state,sep=""))
# break
#print(cbind(state_list,lm_mseS, grf_mseS))
write.csv(total_df,paste(mainDir,"allstates_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
}
clusterExport(cl, list("test_set","county_data"))
for (cutoff in (latest_date - predictionsize-1):(latest_date - predictionsize)){
state_df_list <- list()
lm_mseS<-list()
grf_mseS<-list()
cutoff_S <-list()
state_S <-list()
total_df <- NULL
test_set <- function(state){
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
}
# Validation Set
restricted_state_df1 <- subset(county_data, days_from_start <= cutoff & days_from_start >= cutoff)
# Training Set
restricted_state_df0 <- parLapply(cl,state_list,test_set)
today<-restricted_state_df0[c("date","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
#lm_mseS<-list.append(lm_mseS,sum(restricted_state_df2$lm_mse))
#grf_mseS<-list.append(grf_mseS,sum(restricted_state_df2$grf_mse))
#cutoff_S<-list.append(cutoff_S,cutoff)
#state_S<-list.append(state_S,state)
total_df <- rbind(total_df,restricted_state_df2)
mainDir = "./data/output/"
subDir = state
file_sub = paste(mainDir,subDir,sep="")
dir.create(file.path(mainDir, subDir))
# write.csv(restricted_state_df2,paste(file_sub,"/",state,"_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
#print(paste("Done writing csv for day ", toString(cutoff), " of " ,state,sep=""))
# break
#print(cbind(state_list,lm_mseS, grf_mseS))
write.csv(total_df,paste(mainDir,"allstates_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
}
# Training Set
restricted_state_df0 <- foreach(state=state_list, .combine = rbind)%dopar%{
test_set(state)
}
#for (cutoff in (latest_date - predictionsize-1):(latest_date - predictionsize)){
backtest <- function(cutoff,windowsize = 7,predictionsize = 7){
test_set <- function(state){
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
}
# Validation Set
restricted_state_df1 <- subset(county_data, days_from_start <= cutoff & days_from_start >= cutoff)
# Training Set
restricted_state_df0 <- foreach(state=state_list, .combine = rbind)%dopar%{
test_set(state)
}
today<-restricted_state_df0[c("date","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
mainDir = "./data/output/"
subDir = state
file_sub = paste(mainDir,subDir,sep="")
dir.create(file.path(mainDir, subDir))
write.csv(restricted_state_df2,paste(mainDir,"allstates_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
}
backtest(172)
#for (cutoff in (latest_date - predictionsize-1):(latest_date - predictionsize)){
backtest <- function(cutoff,windowsize = 7,predictionsize = 7){
# Validation Set
restricted_state_df1 <- subset(county_data, days_from_start <= cutoff & days_from_start >= cutoff)
# Training Set
restricted_state_df0 <- foreach(state=state_list, .combine = rbind)%dopar%{
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
}
today<-restricted_state_df0[c("date","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
mainDir = "./data/output/"
subDir = state
file_sub = paste(mainDir,subDir,sep="")
dir.create(file.path(mainDir, subDir))
write.csv(restricted_state_df2,paste(mainDir,"allstates_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
}
backtest(172)
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
warnings()
closeAllConnections()
backtest(172)
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
#for (cutoff in (latest_date - predictionsize-1):(latest_date - predictionsize)){
foreach(cutoff = (latest_date - predictionsize-1):(latest_date - predictionsize))%:%{
# Validation set
restricted_state_df1 <- subset(county_data,days_from_start == cutoff + predictionsize)
# Training Set
restricted_state_df0 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
}
today<-restricted_state_df0[c("date","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
mainDir = "./data/output/"
subDir = state
file_sub = paste(mainDir,subDir,sep="")
dir.create(file.path(mainDir, subDir))
write.csv(restricted_state_df2,paste(mainDir,"allstates_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
}
#for (cutoff in (latest_date - predictionsize-1):(latest_date - predictionsize)){
foreach(cutoff = (latest_date - predictionsize-1):(latest_date - predictionsize))%do%{
# Validation set
restricted_state_df1 <- subset(county_data,days_from_start == cutoff + predictionsize)
# Training Set
restricted_state_df0 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
}
today<-restricted_state_df0[c("date","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
mainDir = "./data/output/"
subDir = state
file_sub = paste(mainDir,subDir,sep="")
dir.create(file.path(mainDir, subDir))
write.csv(restricted_state_df2,paste(mainDir,"allstates_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
}
cutofflist
cutoff_list = (latest_date - predictionsize-1):(latest_date - predictionsize)
length
length(cutoff_list)
cutoff_list[2]
cutoff_list[1]
i = 1
cutoff_list = (latest_date - predictionsize-1):(latest_date - predictionsize)
for (i in 1:length(cutoff_list)){
# Validation set
restricted_state_df1 <- subset(county_data,days_from_start == cutoff + predictionsize)
# Training Set
cutoff = cutoff_list[i]
restricted_state_df0 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
}
today<-restricted_state_df0[c("date","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
mainDir = "./data/output/"
subDir = state
file_sub = paste(mainDir,subDir,sep="")
dir.create(file.path(mainDir, subDir))
write.csv(restricted_state_df2,paste(mainDir,"allstates_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
}
list.of.packages <- c("ggplot2", "Rcpp", "grf", "caret", "mltools", "rpart", "minpack.lm", "doParallel", "rattle", "anytime","rlist")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
list.of.packages <- c(list.of.packages, "zoo", "dtw", "foreach", "evaluate","rlist")
lapply(list.of.packages, require, character.only = TRUE)
# Set Working Directory to File source directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source("county_analysis.R")
registerDoParallel(cores=detectCores())
destfile <- paste("./data/processed_us-counties_",Sys.Date(),".csv",sep="")
county_data <- read.csv(file = destfile)
county_data$datetime <- anytime::anydate(county_data$date)
county_data$log_rolled_cases <- log(county_data$rolled_cases)
state_list = sort(unique(county_data$state))
# switch to state_list for all states, Idaho, California, Massachusetts, Texas
windowsize = 7
predictionsize = 7
#for (cutoff in (earliest_start+windowsize):(latest_date -predictionsize)){
earliest_start = min(county_data$days_from_start)
latest_date = max(county_data$days_from_start)
i = 1
cutoff_list = (latest_date - predictionsize-1):(latest_date - predictionsize)
cutoff = cutoff_list[i]
restricted_state_df0 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
}
View(restricted_state_df0)
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
# Validation set
restricted_state_df1 <- subset(county_data,days_from_start == cutoff + predictionsize)
# Training Set
cutoff = cutoff_list[i]
restricted_state_df0 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
}
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R', echo=TRUE)
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R', echo=TRUE)
foreach(cutoff = (latest_date - predictionsize-1):(latest_date - predictionsize))%:%{
# Validation set
restricted_state_df1 <- subset(county_data,days_from_start == cutoff + predictionsize)
# Training Set
restricted_state_df0 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
}
today<-restricted_state_df0[c("date","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
mainDir = "./data/output/"
write.csv(restricted_state_df2,paste(mainDir,"allstates_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
}
closeAllConnections()
foreach(cutoff = (latest_date - predictionsize-1):(latest_date - predictionsize))%:%{
# Validation set
restricted_state_df1 <- subset(county_data,days_from_start == cutoff + predictionsize)
# Training Set
restricted_state_df0 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
}
today<-restricted_state_df0[c("date","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
mainDir = "./data/output/"
write.csv(restricted_state_df2,paste(mainDir,"allstates_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
}
for(cutoff = (latest_date - predictionsize-1):(latest_date - predictionsize)){
# Validation set
restricted_state_df1 <- subset(county_data,days_from_start == cutoff + predictionsize)
# Training Set
restricted_state_df0 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
}
today<-restricted_state_df0[c("date","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
mainDir = "./data/output/"
write.csv(restricted_state_df2,paste(mainDir,"allstates_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
}
for(cutoff in (latest_date - predictionsize-1):(latest_date - predictionsize)){
# Validation set
restricted_state_df1 <- subset(county_data,days_from_start == cutoff + predictionsize)
# Training Set
restricted_state_df0 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
}
today<-restricted_state_df0[c("date","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
mainDir = "./data/output/"
write.csv(restricted_state_df2,paste(mainDir,"allstates_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
}
closeAllConnections()
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R', echo=TRUE)
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R', echo=TRUE)
print(paste("Starting computation for cutoff=",toString(cutoff),sep=""))
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R', echo=TRUE)
mainDir = "./data/output/"
subDir = "backtest"
dir.create(file.path(mainDir, subDir))
file.path
?file.path
backtest_dir = file.path(mainDir, subDir)
backtest_dir
mainDir = "./data/output"
subDir = "backtest"
backtest_dir = file.path(mainDir, subDir)
dir.create(backtest_dir)
backtest_dir
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R', echo=TRUE)
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R', echo=TRUE)
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R', echo=TRUE)
for(cutoff in (earliest_start+predictionsize+1):(latest_date - predictionsize)){
print(paste("Starting computation for cutoff=",toString(cutoff),sep=""))
# Validation set
restricted_state_df1 <- subset(county_data,days_from_start == cutoff + predictionsize)
# Training Set
restricted_state_df0 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
}
today<-restricted_state_df0[c("date","days_from_start","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","days_from_start","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
print(paste("Finished writing backtest for cutoff=",toString(cutoff),setp=""))
backtest_file_path = file.path(backtest_dir, paste("allstates_",toString(cutoff),"_grf.csv",sep=""))
write.csv(restricted_state_df2,backtest_file_path,row.names=FALSE)
break
}
for(cutoff in (earliest_start+predictionsize+1):(latest_date - predictionsize)){
print(paste("Starting computation for cutoff=",toString(cutoff),sep=""))
restricted_state_df0 <- NULL
restricted_state_df1 <- NULL
# Validation set
restricted_state_df1 <- subset(county_data,days_from_start == cutoff + predictionsize)
# Training Set
restricted_state_df0 <- NULL
try(restricted_state_df0 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
})
if(is.null(restricted_state_df0)){
next
}
today<-restricted_state_df0[c("date","days_from_start","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","days_from_start","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
print(paste("Finished writing backtest for cutoff=",toString(cutoff),setp=""))
backtest_file_path = file.path(backtest_dir, paste("allstates_",toString(cutoff),"_grf.csv",sep=""))
write.csv(restricted_state_df2,backtest_file_path,row.names=FALSE)
break
}
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R', echo=TRUE)
for(cutoff in cutofflist){
print(paste("Starting computation for cutoff=",toString(cutoff),sep=""))
restricted_state_df0 <- NULL
restricted_state_df1 <- NULL
# Validation set
restricted_state_df1 <- subset(county_data,days_from_start == cutoff + predictionsize)
# Training Set
restricted_state_df0 <- NULL
try(restricted_state_df0 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = NULL
k = try(county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize))
return(k)
})
if(is.null(restricted_state_df0)){
next
}
today<-restricted_state_df0[c("date","days_from_start","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","days_from_start","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
print(paste("Finished writing backtest for cutoff=",toString(cutoff),setp=""))
backtest_file_path = file.path(backtest_dir, paste("allstates_",toString(cutoff),"_grf.csv",sep=""))
write.csv(restricted_state_df2,backtest_file_path,row.names=FALSE)
break
}
#cutofflist = (earliest_start+predictionsize+1):(latest_date - predictionsize)
cutofflist = 150:(latest_date - predictionsize)
for(cutoff in cutofflist){
print(paste("Starting computation for cutoff=",toString(cutoff),sep=""))
restricted_state_df0 <- NULL
restricted_state_df1 <- NULL
# Validation set
restricted_state_df1 <- subset(county_data,days_from_start == cutoff + predictionsize)
# Training Set
restricted_state_df0 <- NULL
try(restricted_state_df0 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = NULL
k = try(county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize))
return(k)
})
if(is.null(restricted_state_df0)){
next
}
today<-restricted_state_df0[c("date","days_from_start","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","days_from_start","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
print(paste("Finished writing backtest for cutoff=",toString(cutoff),setp=""))
backtest_file_path = file.path(backtest_dir, paste("allstates_",toString(cutoff),"_grf.csv",sep=""))
write.csv(restricted_state_df2,backtest_file_path,row.names=FALSE)
break
}
closeAllConnections()
for(cutoff in cutofflist){
print(paste("Starting computation for cutoff=",toString(cutoff),sep=""))
restricted_state_df0 <- NULL
restricted_state_df1 <- NULL
# Validation set
restricted_state_df1 <- subset(county_data,days_from_start == cutoff + predictionsize)
# Training Set
restricted_state_df0 <- NULL
try(restricted_state_df0 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = NULL
k = try(county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize))
return(k)
})
if(is.null(restricted_state_df0)){
next
}
today<-restricted_state_df0[c("date","days_from_start","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","days_from_start","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
print(paste("Finished writing backtest for cutoff=",toString(cutoff),setp=""))
backtest_file_path = file.path(backtest_dir, paste("allstates_",toString(cutoff),"_grf.csv",sep=""))
write.csv(restricted_state_df2,backtest_file_path,row.names=FALSE)
break
}
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R', echo=TRUE)
