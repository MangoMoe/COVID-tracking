ls
ls()
install.packages("devtools")
library(devtools)
install_github("susanathey/causalTree")
install.packages("devtools")
library(devtools)
install_github("susanathey/causalTree")
install_github("susanathey/causalTree")
install_github("susanathey/causalTree")
pkgbuild::check_build_tools(debug = TRUE)
library(rpart)
install.packages('rpart')
install_github("susanathey/causalTree")
library(devtools)
install_github("susanathey/causalTree")
install.packages("devtools")
install.packages("devtools")
library(devtools)
install_github("susanathey/causalTree")
install_github("susanathey/causalTree")
library(causalTree)
options(buildtools.check = function(action) TRUE )
library(devtools)
R.version
R.update
install_github("susanathey/causalTree")
install.packages("installr")
library(installr)
updateR()
ls
library(readxl)
cont_data <- read_excel("C:/Users/wangz/Dropbox/Recursive Partitioning IP/experiment/cont_data.csv")
View(cont_data)
cont_data <- read.csv("C:/Users/wangz/Dropbox/Recursive Partitioning IP/experiment/cont_data.csv")
View(cont_data)
setwd("C:/Users/wangz/Dropbox/COVID-tracking")
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
list.of.packages <- c("ggplot2", "Rcpp", "grf", "caret", "mltools", "rpart", "minpack.lm", "doParallel", "rattle", "anytime")
list.of.packages <- c(list.of.packages, "zoo", "dtw", "choroplethr", "choroplethrMaps", "foreach")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
source("county_analysis_function.R")
county_data <- read.csv(file = './data/processed_us-counties.csv')
county_data$datetime <- anytime::anydate(county_data$date)
county_data$log_rolled_cases <- log(county_data$rolled_cases)
restricted_idaho_df = county_analysis("Idaho",county_data , 73)
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
list.of.packages <- c("ggplot2", "Rcpp", "grf", "caret", "mltools", "rpart", "minpack.lm", "doParallel", "rattle", "anytime")
list.of.packages <- c(list.of.packages, "zoo", "dtw", "choroplethr", "choroplethrMaps", "foreach")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
source("county_analysis_function.R")
county_data <- read.csv(file = './data/processed_us-counties.csv')
county_data$datetime <- anytime::anydate(county_data$date)
county_data$log_rolled_cases <- log(county_data$rolled_cases)
restricted_idaho_df = county_analysis("Idaho",county_data , 73)
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
county_data <- read.csv(file = './data/processed_us-counties.csv')
county_data$datetime <- anytime::anydate(county_data$date)
county_data$log_rolled_cases <- log(county_data$rolled_cases)
restricted_idaho_df = county_analysis("Idaho",county_data , 73)
list.of.packages <- c("ggplot2", "Rcpp", "grf", "caret", "mltools", "rpart", "minpack.lm", "doParallel", "rattle", "anytime")
list.of.packages <- c(list.of.packages, "zoo", "dtw", "choroplethr", "choroplethrMaps", "foreach")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
list.of.packages <- c("ggplot2", "Rcpp", "grf", "caret", "mltools", "rpart", "minpack.lm", "doParallel", "rattle", "anytime")
list.of.packages <- c(list.of.packages, "zoo", "dtw", "choroplethr", "choroplethrMaps", "foreach")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# registerDoParallel(cores=6)
county_analysis <- function(state, county_data, cutoff){
state_df = county_data[which(county_data$state==state),]
state_fips_list = sort(unique(state_df$fips))
# Define log linear and double parameter exponent models
log_exp <-function(t,r,t0){r*t-r*t0}
double_exp <- function(t,r,t0){exp(r*t-r*t0)}
earliest_start = min(state_df$days_from_start)
latest_start = earliest_start
for (fips in state_fips_list){
county_df = state_df[which(state_df$fips == fips),]
county_start = min(county_df$days_from_start)
#print(county_start)
if (county_start > latest_start ){
latest_start = county_start
}
}
# Restrict analyses < 80 days from start
# cutoff = 73
restricted_state_df = state_df[which(state_df$days_from_start < cutoff),]
restricted_state_fips_list = sort(unique(restricted_state_df$fips))
rlist = c()
t0list = c()
for (fips in restricted_state_fips_list){
#print(fips)
county_df = restricted_state_df[which(restricted_state_df$fips == fips),]
logmodel = lm(formula = log_rolled_cases ~ days_from_start, data=county_df)
rguess = coef(logmodel)[[2]]
t0guess = coef(logmodel)[[1]]/(-rguess)
#guess = c(r = rguess, t0 = t0guess)
while(TRUE){
expmodel<-NULL
# Note if nls fails, then carry on with r and t0 set to NA
try(expmodel<-nls(formula = rolled_cases ~ double_exp(days_from_start, r, t0), data=county_df, start = c(r = rguess, t0 = t0guess) )); # does not stop in the case of error
if(!is.null(expmodel)){
r = coef(expmodel)[[1]]
t0 = coef(expmodel)[[2]]
rlist = c(rlist, r)
t0list = c(t0list, t0)
break; # if nls works, then quit from the loop
}
r = NA
t0 = NA
rlist = c(rlist,NA)
t0list = c(t0list,NA)
break;
}
restricted_state_df[which(restricted_state_df$fips == fips),"t0"] = t0
restricted_state_df[which(restricted_state_df$fips == fips),"r"] = r
}
# Method 1: Calculate ln(I) = r*t - intercept and feed into GRF
# Method 2: Cluster time series by DTW -> then refit model with exponential model
restricted_state_df = na.omit(restricted_state_df)
tau.forest <-grf::causal_forest(X=restricted_state_df[,c("r","t0")], Y=restricted_state_df[,"log_rolled_cases"], W= restricted_state_df[,"days_from_start"])
# Re-estimated r
restricted_state_fips_list = sort(unique(restricted_state_df$fips))
r.grflist = c()
for (fips in restricted_state_fips_list){
# print(fips)
county_df = restricted_state_df[which(restricted_state_df$fips == fips),]
X.test <- unique(restricted_state_df[which(restricted_state_df$fips == fips), c("r","t0")])
tau.hat <- predict(tau.forest,X.test)
restricted_state_df[which(restricted_state_df$fips == fips), "r.grf"] <- tau.hat
r.grflist = c(r.grflist,tau.hat)
county_df$X <- county_df$days_from_start * tau.hat[[1]]
# Re-estimate t0
t0.hat <- (mean(county_df$log_rolled_cases) - mean(county_df$X))/(-tau.hat)
restricted_state_df[which(restricted_state_df$fips == fips), "t0.grf"] <- t0.hat
}
return(restricted_state_df)
#write.csv(restricted_idaho_df,"./data/idaho_grf.csv",row.names=FALSE)
}
county_data <- read.csv(file = './data/processed_us-counties.csv')
county_data$datetime <- anytime::anydate(county_data$date)
county_data$log_rolled_cases <- log(county_data$rolled_cases)
restricted_idaho_df = county_analysis("Idaho",county_data , 73)
debugSource('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
debugSource('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
View(restricted_idaho_df)
for (fips in restricted_california_fips_list){
# print(fips)
county_df = restricted_california_df[which(restricted_california_df$fips == fips),]
X.test <- unique(restricted_california_df[which(restricted_california_df$fips == fips), c("r","t0")])
tau.hat <- predict(tau.forest,X.test)
restricted_california_df[which(restricted_california_df$fips == fips), "r.grf"] <- tau.hat
r.grflist = c(r.grflist,tau.hat)
county_df$X <- county_df$days_from_start * tau.hat[[1]]
# Re-estimate t0
county_df$X <- county_df$days_from_start * tau.hat[[1]]
# Re-estimate t0
t0.hat <- (mean(county_df$log_rolled_cases) - mean(county_df$X))/(-tau.hat)
restricted_california_df[which(restricted_california_df$fips == fips), "t0.grf"] <- t0.hat
}
write.csv(restricted_idaho_df,"./data/idaho_grf.csv",row.names=FALSE)
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
View(restricted_idaho_df)
View(restricted_idaho_df)
county_data <- read.csv(file = './data/processed_us-counties.csv')
county_data$datetime <- anytime::anydate(county_data$date)
county_data$log_rolled_cases <- log(county_data$rolled_cases)
restricted_idaho_df = county_analysis("Idaho",county_data , 73)
replay(evaluate(file('Specific_Cases.R')))
list.of.packages <- c("ggplot2", "Rcpp", "grf", "caret", "mltools", "rpart", "minpack.lm", "doParallel", "rattle", "anytime")
list.of.packages <- c(list.of.packages, "zoo", "dtw", "choroplethr", "choroplethrMaps", "foreach", "evaluate")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# registerDoParallel(cores=6)
county_analysis <- function(state, county_data, cutoff){
state_df = county_data[which(county_data$state==state),]
state_fips_list = sort(unique(state_df$fips))
# Define log linear and double parameter exponent models
log_exp <-function(t,r,t0){r*t-r*t0}
double_exp <- function(t,r,t0){exp(r*t-r*t0)}
earliest_start = min(state_df$days_from_start)
latest_start = earliest_start
for (fips in state_fips_list){
county_df = state_df[which(state_df$fips == fips),]
county_start = min(county_df$days_from_start)
#print(county_start)
if (county_start > latest_start ){
latest_start = county_start
}
}
# Restrict analyses < 80 days from start
# cutoff = 73
restricted_state_df = state_df[which(state_df$days_from_start < cutoff),]
restricted_state_fips_list = sort(unique(restricted_state_df$fips))
rlist = c()
t0list = c()
for (fips in restricted_state_fips_list){
#print(fips)
county_df = restricted_state_df[which(restricted_state_df$fips == fips),]
logmodel = lm(formula = log_rolled_cases ~ days_from_start, data=county_df)
rguess = coef(logmodel)[[2]]
t0guess = coef(logmodel)[[1]]/(-rguess)
#guess = c(r = rguess, t0 = t0guess)
while(TRUE){
expmodel<-NULL
# Note if nls fails, then carry on with r and t0 set to NA
try(expmodel<-nls(formula = rolled_cases ~ double_exp(days_from_start, r, t0), data=county_df, start = c(r = rguess, t0 = t0guess) )); # does not stop in the case of error
if(!is.null(expmodel)){
r = coef(expmodel)[[1]]
t0 = coef(expmodel)[[2]]
rlist = c(rlist, r)
t0list = c(t0list, t0)
break; # if nls works, then quit from the loop
}
r = NA
t0 = NA
rlist = c(rlist,NA)
t0list = c(t0list,NA)
break;
}
restricted_state_df[which(restricted_state_df$fips == fips),"t0"] = t0
restricted_state_df[which(restricted_state_df$fips == fips),"r"] = r
}
# Method 1: Calculate ln(I) = r*t - intercept and feed into GRF
# Method 2: Cluster time series by DTW -> then refit model with exponential model
restricted_state_df = na.omit(restricted_state_df)
tau.forest <-grf::causal_forest(X=restricted_state_df[,c("r","t0")], Y=restricted_state_df[,"log_rolled_cases"], W= restricted_state_df[,"days_from_start"])
# Re-estimated r
restricted_state_fips_list = sort(unique(restricted_state_df$fips))
r.grflist = c()
for (fips in restricted_state_fips_list){
# print(fips)
county_df = restricted_state_df[which(restricted_state_df$fips == fips),]
X.test <- unique(restricted_state_df[which(restricted_state_df$fips == fips), c("r","t0")])
tau.hat <- predict(tau.forest,X.test)
restricted_state_df[which(restricted_state_df$fips == fips), "r.grf"] <- tau.hat
r.grflist = c(r.grflist,tau.hat)
county_df$X <- county_df$days_from_start * tau.hat[[1]]
# Re-estimate t0
t0.hat <- (mean(county_df$log_rolled_cases) - mean(county_df$X))/(-tau.hat)
restricted_state_df[which(restricted_state_df$fips == fips), "t0.grf"] <- t0.hat
}
return(restricted_state_df)
#write.csv(restricted_idaho_df,"./data/idaho_grf.csv",row.names=FALSE)
}
county_data <- read.csv(file = './data/processed_us-counties.csv')
county_data$datetime <- anytime::anydate(county_data$date)
county_data$log_rolled_cases <- log(county_data$rolled_cases)
restricted_idaho_df = county_analysis("Idaho",county_data , 73)
write.csv(restricted_idaho_df,"./data/idaho_grf.csv",row.names=FALSE)
print("Done writing csv")
closeAllConnections()
replay(evaluate(file('Specific_Cases.R')))
