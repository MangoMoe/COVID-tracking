restricted_state_df[which(restricted_state_df$fips == fips),"r"] = rguess
restricted_state_df[which(restricted_state_df$fips == fips),"r.SE"] = SE_rguess
}
# Method 1: Calculate ln(I) = r*t - intercept and feed into GRF
# Method 2: Cluster time series by DTW -> then refit model with exponential model
restricted_state_df = na.omit(restricted_state_df)
tau.forest <- NULL
num_trees_list = c(2000,4000,6000,8000)
for (num_trees in num_trees_list){
tau.forest <-grf::causal_forest(X=restricted_state_df[,c("r","t0")], Y=restricted_state_df[,"log_rolled_cases"], W= restricted_state_df[,"days_from_start"], num.trees = num_trees)
# Re-estimated r
restricted_state_fips_list = sort(unique(restricted_state_df$fips))
r.grflist = c()
for (fips in restricted_state_fips_list){
# print(fips)
county_df = restricted_state_df[which(restricted_state_df$fips == fips),]
X.test <- unique(restricted_state_df[which(restricted_state_df$fips == fips), c("r","t0")])
tau.hat <- predict(tau.forest,X.test, estimate.variance = TRUE)
sigma.hat <- sqrt(tau.hat$variance.estimates)
restricted_state_df[which(restricted_state_df$fips == fips), paste("r.grf",toString(num_trees),sep="")] <- tau.hat
restricted_state_df[which(restricted_state_df$fips == fips), paste("r.SE.grf",toString(num_trees),sep="")] <- sigma.hat
r.grflist = c(r.grflist,tau.hat)
county_df$X <- county_df$days_from_start * tau.hat[[1]]
# Re-estimate t0
t0.hat <- (mean(county_df$log_rolled_cases) - mean(county_df$X))/(-tau.hat)
restricted_state_df[which(restricted_state_df$fips == fips), paste("t0.grf",toString(num_trees),sep="")] <- t0.hat
}
}
return(restricted_state_df)
#write.csv(restricted_idaho_df,"./data/idaho_grf.csv",row.names=FALSE)
}
for (state in c("Idaho")){
state_df = county_data[which(county_data$state==state),]
earliest_start = min(state_df$days_from_start)
for (cutoff in (earliest_start+7):(earliest_start + 30)){
restricted_state_df <- NULL
try(restricted_state_df <- county_analysis(state, county_data, cutoff))
if(is.null(restricted_state_df)){
next
}
mainDir = "./data/output/"
subDir = state
file_sub = paste(mainDir,subDir,sep="")
dir.create(file.path(mainDir, subDir))
write.csv(restricted_state_df,paste(file_sub,"/",state,"_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
print(paste("Done writing csv for day ", toString(cutoff), " of " ,state,sep=""))
}
}
setwd("C:/Users/wangz/Dropbox/COVID-tracking")
Sys.Data()
Sys.Date()
destfile <- paste("us-counties_",Sys.Date(),".csv",sep="")
destfile
source('C:/Users/wangz/Dropbox/COVID-tracking/Preprocess_us-counties.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Preprocess_us-counties.R')
download.file(nyt_url, destfile, "wget")
# destfile <- paste("./data/us-counties_",Sys.Date(),".csv",sep="")
county_data <- read.csv(nyt_url)
county_data
list.of.packages <- c("ggplot2", "Rcpp", "grf", "caret", "mltools", "rpart", "minpack.lm", "doParallel", "rattle", "anytime")
list.of.packages <- c(list.of.packages, "zoo")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# Set Working Directory to File source directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# URL of NYTimes Data
nyt_url <- "https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"
destfile <- paste("./data/us-counties_",Sys.Date(),".csv",sep="")
county_data <- read.csv(nyt_url)
write.csv(county_data, destfile, row.names=FALSE)
source('C:/Users/wangz/Dropbox/COVID-tracking/Preprocess_us-counties.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
closeAllConnections()
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
warnings()
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
x<-data.frame("cutoff" = cutoff_S, "lm_mse" = lm_mseS, "grf_mse" = grf_mseS)
x<-data.frame( "lm_mse" = lm_mseS, "grf_mse" = grf_mseS)
x
lm_mseS
c(1,2)
print(c(1,2),c(3,4))
print(cbind(c(1,2),c(3,4))
)
source('C:/Users/wangz/Dropbox/COVID-tracking/Preprocess_us-counties.R')
list(c(1,2),c(3,4))
list(c(1,2),c(3,4))[1]
list(c(1,2),c(3,4))[[1]]
list(c(1,2),c(3,4))[[1,2]]
list(c(1,2),c(3,4))[[2]]
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
state_S
c(c(),"State")
c(c("Aka"),"State")
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
detectCores()
doParallel::detectCores()
library(doParallel)
detectCores()
library(list.of.packages)
new.packages
require(list.of.packages)
lapply(list.of.packages, require, character.only = TRUE)
list.of.packages <- c("ggplot2", "Rcpp", "grf", "caret", "mltools", "rpart", "minpack.lm", "doParallel", "rattle", "anytime","rlist")
list.of.packages <- c(list.of.packages, "zoo", "dtw", "choroplethr", "choroplethrMaps", "foreach", "evaluate","rlist")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
require(new.packages)
# require(new.packages)
lapply(list.of.packages, require, character.only = TRUE)
registerDoParallel(cores=6)
detectCores()
registerDoParallel(cores=detectCores())
foreach
county_analysis
restricted_state_df1 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, earliest_start,cutoff + predictionsize,predictionsize)
return(k)
}
restricted_state_df1
unique(restricted_state_df1$fips)
restricted_state_df0 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
}
today<-restricted_state_df0[c("date","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
lm_mseS<-list.append(lm_mseS,sum(restricted_state_df2$lm_mse))
grf_mseS<-list.append(grf_mseS,sum(restricted_state_df2$grf_mse))
cutoff_S<-list.append(cutoff_S,cutoff)
state_S<-list.append(state_S,state)
total_df <- rbind(total_df,restricted_state_df2)
mainDir = "./data/output/"
subDir = state
file_sub = paste(mainDir,subDir,sep="")
dir.create(file.path(mainDir, subDir))
print(paste("Done writing csv for day ", toString(cutoff), " of " ,state,sep=""))
print(cbind(state_S,lm_mseS, grf_mseS))
write.csv(total_df,paste(mainDir,"allstates_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
source('C:/Users/wangz/Dropbox/COVID-tracking/Specific_Cases.R')
print(cbind(state_list,lm_mseS, grf_mseS))
lm_mseS
restricted_state_dfz <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, latest_date-windowsize, latest_date,predictionsize)
return(k)
}
closeAllConnections()
restricted_state_dfz <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, latest_date-windowsize, latest_date,predictionsize)
return(k)
}
restricted_state_dfz <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, latest_date-windowsize, latest_date,predictionsize)
return(k)
}
list.of.packages <- c("ggplot2", "Rcpp", "grf", "caret", "mltools", "rpart", "minpack.lm", "doParallel", "rattle", "anytime","rlist")
list.of.packages <- c(list.of.packages, "zoo", "dtw", "choroplethr", "choroplethrMaps", "foreach", "evaluate","rlist")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only = TRUE)
# Set Working Directory to File source directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
registerDoParallel(cores=detectCores())
county_analysis <- function(state, county_data, cutoffstart,cutoffend, predictionsize){
state_df = county_data[which(county_data$state==state),]
state_fips_list = sort(unique(state_df$fips))
# Define log linear and double parameter exponent models
log_exp <-function(t,r,t0){r*t-r*t0}
double_exp <- function(t,r,t0){exp(r*t-r*t0)}
earliest_start = min(state_df$days_from_start)
latest_start = earliest_start
for (fips in state_fips_list){
county_df = state_df[which(state_df$fips == fips),]
county_start = min(county_df$days_from_start)
#print(county_start)
if (county_start > latest_start ){
latest_start = county_start
}
}
restricted_state_df = subset(state_df, days_from_start <= cutoffend & days_from_start >= cutoffstart)
# print(restricted_state_df)
restricted_state_fips_list = sort(unique(restricted_state_df$fips))
rlist = c()
t0list = c()
for (fips in restricted_state_fips_list){
#print(fips)
county_df = restricted_state_df[which(restricted_state_df$fips == fips),]
logmodel = lm(formula = log_rolled_cases ~ days_from_start, data=county_df)
#print(fips)
#print(coef(summary(logmodel)))
rguess <- NULL
try(rguess <- coef(summary(logmodel))["days_from_start","Estimate"])
if (is.null(rguess)){
rguess <- NA
t0guess <- NA
#      SE_rguess <-NA
predict_guess<-NA
next
}
if (rguess == 0){
t0guess = min(county_df$days_from_start)
sigma_rguess = 0
predict_guess=0
}
else{
t0guess = coef(summary(logmodel))["(Intercept)","Estimate"]/(-rguess)
#guess = c(r = rguess, t0 = t0guess)
#      SE_rguess = coef(summary(logmodel))["days_from_start", "Std. Error"]
predict_guess = log_exp(cutoffend-1,rguess,t0guess)
}
#print(coef(logmodel))
#print(confint(logmodel))
#return(logmodel)
restricted_state_df[which(restricted_state_df$fips == fips),"t0"] = t0guess
restricted_state_df[which(restricted_state_df$fips == fips),"r"] = rguess
#   restricted_state_df[which(restricted_state_df$fips == fips),"r.SE"] = SE_rguess
restricted_state_df[which(restricted_state_df$fips == fips),"lm_predict"] = predict_guess
}
# print(restricted_state_df)
# Method 1: Calculate ln(I) = r*t - intercept and feed into GRF
# Method 2: Cluster time series by DTW -> then refit model with exponential model
restricted_state_df = na.omit(restricted_state_df)
tau.forest <- NULL
# num_trees_list = c(2000)
num_trees =2000
tau.forest <-grf::causal_forest(X=restricted_state_df[,c("r","t0")], Y=restricted_state_df[,"log_rolled_cases"], W= restricted_state_df[,"days_from_start"], num.trees = num_trees)
# Re-estimated r
restricted_state_fips_list = sort(unique(restricted_state_df$fips))
r.grflist = c()
for (fips in restricted_state_fips_list){
# print(fips)
county_df = restricted_state_df[which(restricted_state_df$fips == fips),]
X.test <- unique(restricted_state_df[which(restricted_state_df$fips == fips), c("r","t0")])
tau.hat <- predict(tau.forest,X.test, estimate.variance = TRUE)
sigma.hat <- sqrt(tau.hat$variance.estimates)
#print(tau.hat)
r.grf.string = paste("r.grf","",sep="")
r.SE.grf.string = paste("r.SE.grf","",sep="")
grf.predict.string = paste("grf_predict","",sep="")
t0.grf.string = paste("t0.grf","",sep="")
restricted_state_df[which(restricted_state_df$fips == fips), r.grf.string] <- tau.hat
restricted_state_df[which(restricted_state_df$fips == fips), r.SE.grf.string] <- sigma.hat
r.grflist = c(r.grflist,tau.hat)
county_df$X <- county_df$days_from_start * tau.hat[[1]]
# Re-estimate t0
t0.hat <- (mean(county_df$log_rolled_cases) - mean(county_df$X))/(-tau.hat)
restricted_state_df[which(restricted_state_df$fips == fips), grf.predict.string] <-log_exp(cutoffend+ predictionsize,tau.hat,t0.hat)
restricted_state_df[which(restricted_state_df$fips == fips), t0.grf.string] <- t0.hat
#print(restricted_state_df)
}
restricted_state_df = subset(restricted_state_df, days_from_start == cutoffend)
#print(restricted_state_df)
return(restricted_state_df)
#write.csv(restricted_idaho_df,"./data/idaho_grf.csv",row.names=FALSE)
}
destfile <- paste("./data/processed_us-counties_",Sys.Date(),".csv",sep="")
county_data <- read.csv(file = destfile)
county_data$datetime <- anytime::anydate(county_data$date)
county_data$log_rolled_cases <- log(county_data$rolled_cases)
state_list = sort(unique(county_data$state))
# switch to state_list for all states, Idaho, California, Massachusetts, Texas
windowsize = 7
predictionsize = 7
#for (cutoff in (earliest_start+windowsize):(latest_date -predictionsize)){
earliest_start = min(county_data$days_from_start)
latest_date = max(county_data$days_from_start)
restricted_state_dfz <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, latest_date-windowsize, latest_date,predictionsize)
return(k)
}
restricted_state_dfz
write.csv(restricted_state_dfz,paste(mainDir,"allstates_",toString(latest_date),"_grf.csv",sep=""),row.names=FALSE)
write.csv(restricted_state_dfz,paste(mainDir,"allstates_","latest","_grf.csv",sep=""),row.names=FALSE)
list.of.packages <- c("ggplot2", "Rcpp", "grf", "caret", "mltools", "rpart", "minpack.lm", "doParallel", "rattle", "anytime","rlist")
list.of.packages <- c(list.of.packages, "zoo", "dtw", "choroplethr", "choroplethrMaps", "foreach", "evaluate","rlist")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only = TRUE)
source("county_analysis.R")
# Set Working Directory to File source directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
registerDoParallel(cores=detectCores())
destfile <- paste("./data/processed_us-counties_",Sys.Date(),".csv",sep="")
county_data <- read.csv(file = destfile)
county_data$datetime <- anytime::anydate(county_data$date)
county_data$log_rolled_cases <- log(county_data$rolled_cases)
state_list = sort(unique(county_data$state))
# switch to state_list for all states, Idaho, California, Massachusetts, Texas
windowsize = 7
predictionsize = 7
#for (cutoff in (earliest_start+windowsize):(latest_date -predictionsize)){
earliest_start = min(county_data$days_from_start)
latest_date = max(county_data$days_from_start)
for (cutoff in (latest_date - predictionsize-1):(latest_date - predictionsize)){
state_df_list <- list()
lm_mseS<-list()
grf_mseS<-list()
cutoff_S <-list()
state_S <-list()
total_df <- NULL
restricted_state_df1 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, earliest_start,cutoff + predictionsize,predictionsize)
return(k)
}
restricted_state_df0 <- foreach(state = state_list, .combine=rbind) %dopar%{
k = county_analysis(state, county_data, cutoff-windowsize, cutoff,predictionsize)
return(k)
}
today<-restricted_state_df0[c("date","county","state","fips","r","t0","lm_predict","r.grf","t0.grf","grf_predict")]
tomorrow<-restricted_state_df1[c("date","fips","log_rolled_cases")]
restricted_state_df2<-merge(x=today,y=tomorrow,by="fips",x.all=TRUE)
restricted_state_df2$lm_mse<-with(restricted_state_df2,(lm_predict-log_rolled_cases)**2)
restricted_state_df2$grf_mse<-with(restricted_state_df2,(grf_predict-log_rolled_cases)**2)
#lm_mseS<-list.append(lm_mseS,sum(restricted_state_df2$lm_mse))
#grf_mseS<-list.append(grf_mseS,sum(restricted_state_df2$grf_mse))
#cutoff_S<-list.append(cutoff_S,cutoff)
#state_S<-list.append(state_S,state)
total_df <- rbind(total_df,restricted_state_df2)
mainDir = "./data/output/"
subDir = state
file_sub = paste(mainDir,subDir,sep="")
dir.create(file.path(mainDir, subDir))
# write.csv(restricted_state_df2,paste(file_sub,"/",state,"_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
#print(paste("Done writing csv for day ", toString(cutoff), " of " ,state,sep=""))
# break
#print(cbind(state_list,lm_mseS, grf_mseS))
write.csv(total_df,paste(mainDir,"allstates_",toString(cutoff),"_grf.csv",sep=""),row.names=FALSE)
}
list.of.packages <- c("ggplot2", "Rcpp", "grf", "caret", "mltools", "rpart", "minpack.lm", "doParallel", "rattle", "anytime","rlist")
list.of.packages <- c(list.of.packages, "zoo", "dtw", "choroplethr", "choroplethrMaps", "foreach", "evaluate","rlist")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only = TRUE)
source("county_analysis.R")
# Set Working Directory to File source directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
registerDoParallel(cores=detectCores())
destfile <- paste("./data/processed_us-counties_",Sys.Date(),".csv",sep="")
county_data <- read.csv(file = destfile)
county_data$datetime <- anytime::anydate(county_data$date)
county_data$log_rolled_cases <- log(county_data$rolled_cases)
state_list = sort(unique(county_data$state))
# switch to state_list for all states, Idaho, California, Massachusetts, Texas
windowsize = 7
predictionsize = 7
#for (cutoff in (earliest_start+windowsize):(latest_date -predictionsize)){
earliest_start = min(county_data$days_from_start)
latest_date = max(county_data$days_from_start)
source('C:/Users/wangz/Dropbox/COVID-tracking/Analyse_Predictions.R')
# Load Data
mainDir = "./data/output/"
write.csv(total_df,paste(mainDir,"allstates_","latest","_grf.csv",sep=""),row.names=FALSE)
write.csv(total_df,paste(mainDir,"allstates_","latest","_grf.csv",sep=""),row.names=FALSE)
write.csv(allstates_latest_df,paste(mainDir,"allstates_","latest","_grf.csv",sep=""),row.names=FALSE)
View(allstates_latest_df)
# Combine with counties that are not included in allstates_latest_df
prediction_df <- allstates_latest_df
ln(2)
log(2)
log(2,1)
log(2,10)
log(100,10)
log(e,e)
log(exp,exp)
prediction_df["Double_Days"] <- log(2,exp(1))/prediction_df["r.grf"]
View(prediction_df)
length(unique(county_data$fips))
length(unique(county_data$fips))
length(unique(county_data$fips))
length(unique(prediction_df$fips))
OutbreakClass <- function(Double_Days){
# Less than or equal to 3 days is outbreak
if (Double_Days <= 3){
return(2)
}
if (3 < Double_Days & Double_Days <=7)
return(1)
else{
return(0)
}
}
prediction_df["Outbreak_Class"] <- lapply(prediction_df["Double_Days"], OutbreakClass)
u
prediction_df["Outbreak_Class"] <- lapply(prediction_df["Double_Days"], OutbreakClass)
OutbreakClass([1])
OutbreakClass(c(1,2))
OutbreakClass(1)
OutbreakClass(3)
OutbreakClass(023)
OutbreakClass(6.999)
prediction_df["Double_Days"]
prediction_df["Outbreak_Class"] <- apply(prediction_df["Double_Days"], OutbreakClass)
prediction_df["Outbreak_Class"] <- apply(prediction_df,c("Double_Days"), OutbreakClass)
prediction_df["Outbreak_Class"] <- apply(prediction_df,c(2), OutbreakClass)
prediction_df["Outbreak_Class"] <- lapply(prediction_df[["Double_Days"]], OutbreakClass)
unique(prediction_df$Outbreak_Class)
prediction_df[["Double_Days"]]
lapply(prediction_df[["Double_Days"]], OutbreakClass)
data.frame("Outbreak_Class" = lapply(prediction_df[["Double_Days"]], OutbreakClass))
prediction_df[["Double_Days"]]
class_list <- lapply(prediction_df[["Double_Days"]], OutbreakClass)
class_list
class_list[1]
class_list[2]
class_list[[2]]
class_list[[3]]
class_list[[3]]
unique(class_list)
unlist(class_list)
prediction_df["Outbreak_Class"] <- unlist(class_list)
prediction_df.loc[which(prediction_df["Outbreak_Class"] == 2),]
prediction_df[which(prediction_df["Outbreak_Class"] == 2),]
prediction_df[which(prediction_df["Outbreak_Class"] == 1),"county"]
prediction_df[which(prediction_df["Outbreak_Class"] == 2),"county"]
prediction_df[which(prediction_df["Outbreak_Class"] == 2),"fips"]
prediction_df[which(prediction_df["fips"] == 8087),]
county_data[which(county_data["fips"]==8087),c("days_from_start","log_rolled_cases")]
county_data[which(county_data["fips"]==8087),c("days_from_start","rolled_cases")]
inspect_2 <- prediction_df[which(prediction_df["Outbreak_Class"] == 2),]
View(inspect_2)
OutbreakClass <- function(Double_Days){
# Less than or equal to 3 days is outbreak
if (0 <= Double_Days <= 3){
return(2)
}
else if (3 < Double_Days & Double_Days <=7)
return(1)
else{
return(0)
}
}
OutbreakClass <- function(Double_Days){
# Less than or equal to 3 days is outbreak
if (0 <= Double_Days & Double_Days <= 3){
return(2)
}
else if (3 < Double_Days & Double_Days <=7)
return(1)
else{
return(0)
}
}
# Combine with counties that are not included in allstates_latest_df
prediction_df <- allstates_latest_df
prediction_df["Double_Days"] <- log(2,exp(1))/prediction_df["r.grf"]
class_list <- lapply(prediction_df[["Double_Days"]], OutbreakClass)
prediction_df["Outbreak_Class"] <- unlist(class_list)
inspect_2 <- prediction_df[which(prediction_df["Outbreak_Class"] == 2),]
inspect_1 <- prediction_df[which(prediction_df["Outbreak_Class"] == 1),]
View(inspect_1)
predict_df[which(predict_df["county"]=="Ada"),]
prediction_df[which(prediction_df["county"]=="Ada"),]
county_data[which(county_data["fips"]==16015),c("days_from_start","rolled_cases")]
county_data[which(county_data["fips"]==48137),c("days_from_start","rolled_cases")]
outbreak_df <- subset(prediction_df, c("date","fips","county","state","Outbreak_Class"))
outbreak_df <- prediction_df[c("date","fips","county","state","Outbreak_Class")]
View(outbreak_df)
source('C:/Users/wangz/Dropbox/COVID-tracking/Generate_Predictions_grf.R')
write.csv(outbreak_df,paste(mainDir,"allstates_","ourbreak","_prediction.csv",sep=""),row.names=FALSE)
